\documentclass[polish]{standalone}
\usepackage{thesis}

\begin{document}
\pagestyle{headings}

\chapter{Teoria}

W tym rozdziale zajmiemy się podstawowymi pojęciami i problemami z zakresu teorii gier, jak również przedstawieniem
rozwiązujących je algorytmów, których wykorzystanie było rozważane. Wyjaśnimy też pokrótce sposób działania tych
algorytmów.

\section{Wprowadzenie}

Przez \textit{grę} rozumiemy matematyczny opis pewnej sytuacji konfliktowej, w której biorą udział określone strony,
nazywane \textit{graczami}. Każdej stronie przypisujemy pewien zbiór \textit{strategii}, z którego w danej chwili dana
strona w danym momencie wykorzystuje jedną. Każdemu z graczy przypisujemy również \textit{funkcję wypłaty}, której
wartość uzależniona jest od wszystkich strategii granych przez graczy w określonej chwili. Gracze, ich strategie oraz
funkcje wypłat są definiowane przez nas w ramach danego problemu. \textit{Teoria gier} zajmuje się badaniem właściwości
różnych wariantów tak rozumianych gier.

W zależności od rodzaju rozpatrywanej gry, formalna definicja wymienionych pojęć jest nieco inna. W tej pracy rozważane
będą dwa rodzaje gier: \textit{gry w postaci strategicznej} oraz \textit{gry w postaci ekstensywnej}. Dla obu z nich
możliwe jest zdefiniowanie tzw. \textit{równowagi Nasha}, tj. takiej kombinacji wyborów strategii przez graczy, aby dla
każdego z nich nieopłacalne było odstąpienie od obecnie granej strategii. Pojęcia te wytłumaczymy dokładniej za chwilę.

Teoria gier nie ogranicza się do szukania równowag Nasha. My jednak skupimy się na odnajdywaniu ich w grach, dla
których możliwe jest znalezienie rozwiązania przy pomocy programowania liniowego/całkowitoliczbowego lub rekurencyjnego
przeszukiwania przestrzeni rozwiązań.

\section{Gra w postaci strategicznej}

\begin{definition}
\textbf{Grą w postaci strategicznej (normalnej)}\INENG{strategic-form (normal-form) game} nazywamy trójkę
$(I, S_i, u_i)$, gdzie:
\begin{enumerate}
\item $I = \{ 1, 2, 3, ..., n \}$ - skończony zbiór $n$-graczy,
\item $S_i$ - przestrzeń strategii czystych\INENG{pure strategy} zdefiniowana dla każdego gracza $i \in I$,
\item $u_i(s)$ - funkcja wypłaty\INENG{payoff function} określająca wypłatę gracza $i \in I$ dla każdego profilu
$s \in S$.
\end{enumerate}
\cite[str.~4]{FT-GT}
\end{definition}

Przez strategię czystą rozumiemy wybór na jaki może zdecydować się dana strona - w danej chwili może ona grać tylko
jedną strategią. Kombinację strategii wybranych przez graczy w danej chwili nazywamy \textit{profilem} i zapisujemy:
$$s = (s_1, s_2, ..., s_n)$$
Oznacza to, że gracz $1$ gra $s_1$, gracz $2$ gra $s_2$, itd. Podobnie
$$S = S_1 \times S_2 \times ... \times S_n$$
jest zapisem zbioru wszystkich możliwych profili $s$.

Możemy przyjąć, że dla tak przyjętych oznaczeń, $s_i$ oznacza wybór $i$-tego gracza dla profilu $s$, a $s_{-i}$ opisywać
będzie profil wszystkich wyborów oprócz wyboru gracza $i$:
$$s_{-i} = (s_1, s_2, ..., s_{i-1}, s_{s+1}, ..., s_n)$$
Analogicznie
$$S_{-i} = S_1 \times ... S_{i-1} \times S_{i+1} \times ... \times S_n$$
oznaczać będzie profil wszystkich możliwych odpowiedzi na decyzję gracza $i$.

Przy tak zdefiniowanej grze zakładamy, że najpierw każdy z graczy równocześnie decyduje się na jedną ze swoich
strategii, a następnie na podstawie wyborów podjętych przez wszystkich graczy określamy wypłatę dla każdego z nich.
W całym rozdziale będziemy też zakładać, że gracze są racjonalni, tzn. zawsze dążą do maksymalizacji swojej wypłaty.

\begin{definition}
\textbf{Strategią mieszaną}\INENG{mixed strategy} gracza $i$ nazywamy rozkład $\sigma_i$ nad strategiami czystymi
$S_i$. Za pomocą $\sigma^{*}$ oznaczymy profil strategii mieszanych pozostałych graczy. Wówczas funkcja wypłaty ma
postać $u_i(\sigma_i, \sigma^{*})$ i jest równa wartości oczekiwanej funkcji wypłat dla strategii mieszanych wszystkich
graczy.
\cite[str.~5]{FT-GT}
\end{definition}

\subsection{Równowagi w strategiach czystych}

\begin{definition}
\textbf{Równowagą Nasha\INENG{Nash equilibrium} w strategiach czystych} w grze w postaci strategicznej nazywamy profil
strategii $s \in S$ taki, że:
$$(\forall_{i \in I}) (\forall_{s_{-i} \in S_{-i}}) u_i(s) \geq u_i(s_i, s_{-i})$$
\cite[str.~11]{FT-GT}
\end{definition}

Oznacza to, że równowagą jest profil strategii, dla którego żadnemu z graczy nie opłaca się odstępować od swojej strategii, jeśli założy, że pozostali gracze również przystaną przy swoich strategiach.

Równowaga taka nie zawsze istnieje, czego przykładem jest gra w papier-kamień-nożyce:
\begin{center}
\begin{tabular}[t]{| c                      | c      | c      | c      |}
\hline
                     \diagbox{$p_1$}{$p_2$} & papier & kamień & nożyce \\
\hline
                     papier                 &  0,  0 &  1, -1 & -1,  1 \\
\hline
                     kamień                 & -1,  1 &  0,  0 &  1, -1 \\
\hline
                     nożyce                 &  1, -1 & -1,  1 &  0,  0 \\
\hline
\end{tabular}
\end{center}

W takiej sytuacji każdy z graczy zawsze może zmienić swoją strategię na taką, w której jego wypłata zostanie zwiększona.

Problem szukania równowagi w strategiach czystych nie ma wydajnego rozwiązania \cite[str.~16]{FT-GT}. Wszystko, co
możemy zrobić, to zoptymalizować algorytm siłowy\INENG{brute force} poprzez eliminację strategii zdominowanych
\cite[str.~9--11]{FT-GT}.

\begin{definition}
\textbf{Strategia (słabo) zdominowana} to taka strategia $s_i \in S_i$, że dowolna strategia $s'_i$ jest równie dobra,
jeśli nie lepsza od niej:
$$(\exists_{s'_i}) (\forall_{s_{-i} \in S}) u_i(s_i, s_{-i}) \leq u_i(s'_i, s_{-i})$$
\cite[str.~6--7]{FT-GT}
\end{definition}

\begin{definition}
\textbf{Strategia ściśle zdominowana} to taka strategia $s_i \in S_i$, że dowolna strategia $s'_i$ jest lepsza od niej:
$$(\exists_{s'_i}) (\forall_{s_{-i} \in S}) u_i(s_i, s_{-i}) < u_i(s'_i, s_{-i})$$
\cite[str.~6--7]{FT-GT}
\end{definition}

\begin{definition}
\textbf{Strategia (ściśle) warunkowo zdominowana} to taka strategia $s_i \in S_i$, że wszystkie strategie z danego
podzbioru $S_{-i}' \subseteq S_{-i}$ są lepsze:
$$(\exists_{s'_i}) (\forall_{s_{-i} \in S_{-i'}}) u_i(s_i, s_{-i}) < u_i(s'_i, s_{-i})$$
\cite[str.~2]{PNS-NE}
\end{definition}

Strategie ściśle zdominowane zawsze mogą zostać zastąpione przez jakąś inną strategię, więc szukając punktu równowagi
Nasha możemy je pominąć w rozważaniach, gdyż z definicji nie mogą one wchodzić w skład szukanego profilu. (Ściśle
mówiąc możemy wyeliminować wszystkie strategie ściśle zdominowane oraz większość z słabo zdominowanych. Możliwe jest
jednak wchodzenie w skład równowagi Nasha jednej bądź więcej strategi słabo zdominowanych).

\textbf{Metoda eliminacji strategii zdominowanych} wykorzystuje ten fakt do usuwania tych strategii z rozważanej gry
tak długo, aż zostaną wyłącznie strategie niezdominowane. Zdarza się, że prowadzi to do sytuacji, gdzie równowaga jest
oczywista, ale często konieczne jest jednak przeszukiwanie pozostałej przestrzeni rozwiązań aż do znalezienia
równowagi lub stwierdzenia jej braku.

\subsection{Równowagi w strategiach mieszanych}

\begin{theorem}
\textbf{Twierdzenie Nasha o istnieniu równowagi} - każda skończona gra $(I, S_i, u_i)$ ma równowagę w strategiach
mieszanych.
\cite[str.~29]{FT-GT}
\end{theorem}

Fakt ten dowodzony jest to przy pomocy \textbf{twierdzenia Kakutaniego o punkcie stałym} \cite[str.~29]{FT-GT}.

Gwarantuje nam to możliwość znalezienia równowagi (w strategiach mieszanych) w każdej grze skończonej, nie mówi nam
jednak jak je znaleźć. Szukanie równowag wydaje się być problemem trudnym, nie ma jednak dokładnych oszacowań złożoności
tego problemu \cite{P-AGI}.

\subsubsection{Równowagi w strategiach mieszanych w grach jednomacierzowych}

\begin{definition}
\textbf{Gra o sumie zerowej} to taka gra, że:
$$(\forall_{s \in S}) \sum_{i \in I} u_i(s) = 0$$
\cite[str.~4]{FT-GT}
\end{definition}

Gdy w grze bierze udział dwóch graczy, wartości ich wypłat będą dokładnie przeciwne, można więc funkcję wypłaty zapisać
przy pomocy pojedynczej macierzy $A_{ij}$ (stąd inna nazwa tego typu gier - gry jednomacierzowe\INENG{matrix games}),
gdzie $i$ oznacza wybór strategii czystej pierwszego gracza, a $j$ wybór gracza drugiego. Wartość stanowi wypłatę
pierwszego z graczy.

W takiej sytuacji pierwszy z graczy będzie dążył do maksymalizacji swojej wypłaty, zaś gracz drugi do minimalizacji
wypłaty przeciwnika:

$$\max_{\sigma_1} \{ \min_{j \in J} u_1(\sigma_1, j) \}$$
$$\min_{\sigma_2} \{ \max_{i \in I} u_2(i, \sigma_2) \}$$

Zagadnienia te należą więc to kategorii problemów optymalizacyjnych, tj. takich w których minimalizujemy
(maksymalizujemy) wartość zadanej funkcji, zwanej \textit{funkcją celu}, poprzez dobór odpowiednich wartości jej
parametrów, przy zachowaniu nałożonych na nie ograniczeń. \cite[str.~41]{O-GT} Dla pierwszego gracza możemy to zapisać:

$$\max_{\sigma_1} \{ \min_{j \in J} \sum_{i \in I} A_{ij} \sigma_1(i) \}$$
$$\sum_{i \in I} \sigma_1(i) = 1$$
$$(\forall_{i \in I}) \sigma_1(i) \geq 0$$

Tak zdefiniowany problem możemy przekształcić do postaci \textit{programowania liniowego}\INENG{linear programming}
(LP). \cite[str.~62]{O-GT} Jest to kategoria problemów optymalizacyjnych, w której zarówno funkcja celu jak
i ograniczenia nałożone na rozpatrywane zmienne są zdefiniowane jako liniowe kombinacje owych zmiennych. W
interesującym nas przypadku zadanie to przyjmuje następującą formę:

$$\max_{\sigma_1,v} v$$
$$(\forall_{j \in J}) \sum_{i \in I} A_{ij} \sigma_1(i) \geq v$$
$$\sum_{i \in I} \sigma_1(i) = 1$$
$$(\forall_{i \in I}) \sigma_1(i) \geq 0$$

Dla każdej strategii czystej gracza $i$ obliczyliśmy wartość oczekiwaną wypłaty uzyskanej przy obecnej strategi
mieszanej gracza $-i$. Następnie wybraliśmy najmniejszą z nich - $v$ jest właśnie ograniczeniem dolnym oczekiwanej
wypłaty jaką możemy dostać przy obecnej strategii mieszanej przeciwnika. Tak zapisany problem przekształćmy jednak do
nieco innej postaci, w której można zaobserwować jego ciekawą właściwość. Podstawmy najpierw $x_i = 
\frac{\sigma_1(i)}{v}$:

$$\max_{\sigma_1,v} v$$
\begin{equation}
(\forall_{j \in J}) \sum_{i \in I} A_{ij} x_1(i) \geq 1 \label{MTRX1a}
\end{equation}
\begin{equation}
\sum_{i \in I} x_1(i) = \frac{1}{v} \label{MTRX1b}
\end{equation}
\begin{equation}
(\forall_{i \in I}) x_1(i) \geq 0 \label{MTRX1c}
\end{equation}

Dzieląc wszystkie składniki sumujące się do $v$ przez $v$ uzyskaliśmy równanie sumujące się do $1$ co jest dla nas
bardzo istotne. Staje się to jasne po dokonaniu ostatniego przekształcenia już do docelowej postaci problemu
\cite[str.~63]{O-GT}:

$$\min_x \sum_{i \in I} x_i$$
\begin{equation}
A^Tx \geq 1 \label{MTRX2a}
\end{equation}
\begin{equation}
x \geq 0 \label{MTRX2b}
\end{equation}

W warunku \ref{MTRX1a} sumę zamieniliśmy na wynik mnożenia macierzy przez wektor (\ref{MTRX1a}). W warunku \ref{MTRX1b}
zauważyliśmy, że $v$ stało się dzielnikiem, a więc maksymalizując go, minimalizujemy sumę - mogliśmy więc usunąć ten
warunek przez zmianę funkcji celu. W ostatnim warunku (\ref{MTRX1c}) przeskalowanie zmiennej nie zmieniło ograniczenia
$\geq 0$ i jej podmiana wystarczyła do zakończenia przekształcenia (\ref{MTRX2b}). Należy jedynie pamiętać, że od tego
momentu funkcja celu oblicza $\frac{1}{v}$. Przeprowadzając analogiczne rozumowanie dla gracza drugiego otrzymamy:

$$\max_y \sum_{j \in J} y_i$$
$$Ay \leq 1 $$
$$y \geq 0$$

Okazuje się więc, że są to \textit{problemy dualne}. \cite[str.~42--47]{O-GT} Odpowiednia implementacja algorytmu
\textit{simpleks}, rozwiązującego problemy LP, jest w stanie otrzymać oba rozwiązania przy jednym uruchomieniu
procedury \cite[str.~49--61]{O-GT}. Należy jedynie pamiętać, aby otrzymane wartości podzielić przez wartość funkcji
celu (a więc pomnożyć przez odwrotność $v$), aby wrócić do ich oryginalnej postaci.

\subsubsection{Równowagi w strategiach mieszanych w grach dwumacierzowych}

Dla gier dwumacierzowych\INENG{bimatrix games} (gier 2-osobowych o sumie dowolnej) sytuacja się komplikuje. Istnieje
kilka opisanych algorytmów, które pozwalają na znalezienie równowagi Nasha. Wśród najczęściej wymienianych są to:
\begin{description}
\item[algorytm Lemkego-Howsona] wykorzystujący podprocedurę \textit{pivot} algorytmu simpleksowego \cite{LH-NE};
\item[algorytm Portera-Nudelmana-Shohama (PNS)] korzystający z przeszukiwania z nawrotami oraz programowania liniowego
(wersja dla liczby graczy $n > 2$ jest nieliniowa) \cite{PNS-NE};
\item[algorytm Sandholma-Gilpina-Conitzera] wykorzystujący programowanie całkowitoliczbowe \cite{SCG-NE}.
\end{description}

Prawdopodobnie najbardziej rozpowszechnioną metodą szukania rozwiązań gier dwumacierzowych jest algorytm
\textbf{Lemkego-Howsona}\cite{LH-NE}. Korzysta on z podprocedury \textit{pivot} programowania liniowego, co upodabnia
go do algorytmu simpleks. Pierwotnie pojawił się jako dowód konstrukcyjny istnienia równowag w grach 2-osobowych o sumie
dowolnej.

Na początku zanotujmy, że wartości oczekiwane wypłat graczy $i$ oraz $j$, przy strategiach mieszanych zapisanych jako
wektory prawdopodobieństw, odpowiednio $x$ oraz $y$ wynoszą:
$$u_i = \sum_{s_i in S_i}\sum_{s_j \in S_j} x_{s_i}^{T} A_{i,j} y_{s_j}$$
$$u_j = \sum_{s_i in S_i}\sum_{s_j \in S_j} x_{s_i}^{T} B_{i,j} y_{s_j}$$
gdzie $A$ to macierz wypłat gracza $i$, zaś $B$ macierz wypłat gracza $j$.

Możemy to przepisać na równoważne formy macierzowe:

\begin{equation}
u_i = x^{T} A y \label{LHa1}
\end{equation}
\begin{equation}
u_j = x^{T} B y \label{LHa2}
\end{equation}

Wówczas równowaga Nasha $(x_0, y_0)$ gdy:
$$(\forall_{x,y}) x_0^T A y_0 \geq x^T A y_0$$
$$(\forall_{x,y}) x_0^T A y_0 \geq x_0^T A y$$

W dowodzie wykorzystuje się ten fakt, aby pokazać że nie jest możliwe ogólne rozwiązanie gier dwumacierzowych przy
pomocy programowania liniowego przy przyjętym opisie problemu (nie wyklucza to jednak istnienia inaczej zapisanego
rozwiązania np. całkowitoliczbowego, co pokazuje algorytm SGC).

Ideą stojącą za przedstawionym przez autorów algorytmem jest zapisanie problemu jako \textit{problemu komplementarności
liniowej}\INENG{linear complementarity problem} (LCP), a następnie znalezieniu jego rozwiązania. Problem taki ma postać:
\begin{equation}
w = M z + q \label{LCP1}
\end{equation}
\begin{equation}
w \geq 0 \label{LCP2}
\end{equation}
\begin{equation}
z \geq 0 \label{LCP3}
\end{equation}
\begin{equation}
(\forall_i) w_i z_i = 0 \label{LCP4}
\end{equation}
Szukamy w nim takich wektorów $w$ oraz $z$, aby przy podanej macierzy $M$ oraz wektorze $q$, nierówności były spełnione.
Nierówność \ref{LCP4} odpowiada za \textit{komplementarność}, stąd też nazwa klasy problemów. Istotnie, autorzy pracy
pokazali, że problem można zapisać w formie LCP:
\begin{equation}
\begin{pmatrix}
0 & B^T \\
A & 0 \\
\end{pmatrix}
\begin{pmatrix}
y \\
x \\
\end{pmatrix}
-
\begin{bmatrix}
1  \\
...\\
1  \\
\end{bmatrix}
= r
\label{LHb1}
\end{equation}
\begin{equation}
\begin{pmatrix}
y \\
x \\
\end{pmatrix}
\geq 0 \label{LHb2}
\end{equation}
\begin{equation}
r \geq 0 \label{LHb3}
\end{equation}
\begin{equation}
\begin{pmatrix}
y \\
x \\
\end{pmatrix}^T
r
 = 0 \label{LHb4}
\end{equation}

Proponowane rozwiązanie opera się na spostrzeżeniu, że każde z $l$ ograniczeń opisuje ścianę wielowymiarowej figury
wypukłej. Spełnienie wszystkich obwarowań jest więc znalezieniem punktu, który należy do $l$ ścian tego wielomianu -
wierzchołka w którym się one spotykają. Ponieważ nie wszystkie wierzchołki stanowią rozwiązanie, musimy wybrać jeden, a
następnie przechodzić od wierzchołka do wierzchołka, aż któryś spełni postawione wymagania. Odpowiada za to procedura
\textit{pivot}, wykorzystywana również w algorytmie simpleks.

Najpierw zapis \ref{LHb1} jest wykorzystany do utworzenia macierzy rozszerzonej $D = [d_{ij}]$:
\begin{center}
\begin{tabular}[t]{ | c                       c      | c    | c                  }
                      \multicolumn{2}{|c|}{v}        &      &                    \\
\hline
                      $0$                     & $-A$ &  $1$ & \multirow{2}{*}{w} \\
                      $-B^T$                  & $0$  &  $1$ &                    \\
\hline
\end{tabular}
\end{center}
Początkowo nadajemy wszystkim elementom wektora $z$ wartość $0$, tak więc wektor $r$ składa się z samych $-1$. Po
pomnożeniu obu stron równania przez $-1$ otrzymaliśmy powyższą reprezentację (wiersz jedynek wyznacza wartości $r$).
W tej reprezentacji wektory $v = [ v_1, ..., v_{m+n} ]$ oraz $w = [ w_1, ..., w_{m+n} ]$ (gdzie $m$ i $n$ to ilości
strategii czystych kolejno pierwszego i drugiego gracza) stanowią etykiety, pomocne przy opisie algorytmu. Wartości $r$
stanowią rozwiązanie LCP, ale nie wyznaczają równowagi Nasha - jest to jeden z wierzchołków wielościanu, z którego
możemy rozpocząć poszukiwanie wierzchołka docelowego. Wykonajmy teraz procedurę \textit{pivota}, która przesunie nas
do następnego wierzchołka.

Najpierw znajdźmy element usuwany z bazy (usuwany z pierwotnego wektora $v$-ów) - wybierzmy dowolną kolumną $j_0$.
Następnie wybieramy wiersz $i_0$, tak aby element $d_{i_0,j_0} < 0$ oraz $\frac{d_{i_0,l+1}}{-d_{i+0,j_0}}$ najmniejsze
możliwe (\textit{test najmniejszego ilorazu}). Skalujemy dla niego wiersz macierzy $D$, aby element stał się równy $1$.
Tak przeskalowany wiersz wykorzystujemy do sprowadzenia wszystkich innych elementów znajdujących się w tej samej
kolumnie do wartości $-d_{i_0,j_0}$. Po tej operacji etykiety $v_j$ oraz $w_i$ wymieniają się miejscami. W następnym
kroku wybieramy kolumnę $v$, o indeksie odpowiadającym etykiecie $w$ z bieżącego kroku o ile jej numer jest różny od
numeru etykiety $v$ wybranej na samym początku.

Procedurę powtarzamy tak długo, aż pozycja etykiety $w$ wymienionej w danej iteracji będzie równa pozycji pierwszej
wybranej do zamiany etykiety $v$. Wówczas algorytm się kończy i możemy odczytać rozwiązanie z tabeli: dla zmiennych
których etykiety $v_i$ pozostały na swoich miejscach $r_i = 0$, dla pozostałych przyjmują wartości odpowiedniego
elementu wektora zawierającego pierwotnie jedynki. Wówczas $r = [ x' y' ]$. Po znormalizowaniu $x'$ i $y'$ do $x$ i $y$
(przeskalowaniu ich tak, aby $\sum_{x_i} = 1$ oraz $\sum_{y_i} = 1$), otrzymane $(x, y)$ będzie szukaną równowagą Nasha.

Algorytm \textbf{Portera-Nudelmana-Shohama}\cite{PNS-NE} dla dwóch graczy wykorzystuje fakt, że problem sprawdzenia,
czy istnieje równowaga Nasha w strategiach mieszanych dla określonych strategii czystych z niezerowym
prawdopodobieństwem (w pracy nazywanych \textit{określonym wsparciem}\INENG{particular support}), jest względnie
prostym problemem spełnialności. Przestrzeń takich profili jest przeszukiwana z nawrotem pod kątem spełniania
zdefiniowanych ograniczeń.

W dalszej części będziemy używali oznaczenia $x_{\sigma_i}$ na oznaczenie profilu strategii wspierających strategię
mieszaną $\sigma_i$ tj. zbiór strategii czystych $s_i$ gracza $i$ dla których prawdopodobieństwo $\sigma_i(s_i)$ jest
niezerowe. Profil równowagi Nasha oznaczymy jako $s^{*}$, zaś wartość oczekiwaną wypłaty gracza $i$ dla równowagi jako
$v_i$.

Zakłada się, że żaden z graczy nie preferuje jakiejkolwiek strategii (nie wybiera żadnej strategii czystej z
prawdopodobieństwem $1$). Ze względu na wykorzystane w rozwiązaniu ograniczenie $\sigma_{-i}(s_{-i}) = \prod_{j \ne i}
\sigma_j(s_j)$ problem jest liniowy dla $n = 2$ oraz nieliniowy dla $n > 2$.

Do sprawdzania czy profil wspierający spełnia definicję równowagi Nasha używany jest \textbf{Algorytm \ref{FEASNE}}.
\begin{algorithm}
\caption{Spełnialność równowagi Nasha dla profilu wspierającego}
\label{FEASNE}
\begin{algorithmic}
\REQUIRE{$S = (S_1, ..., S_n)$, profil wspierający}
\ENSURE{równowaga Nasha $s^{*} = (\sigma_1, \sigma_2)$ jeśli istnieje zarówno profil strategii $s$ jak i wartość
$v = (v_1, ..., v_n)$, takie, że:}
$$(\forall_{i \in I, s_i \in S_i}) \sum_{s_{-i} \in S_{-i}} \sigma_{-i}(s_{-i}) u_i(s_i, s_{-i}) = v_i$$
$$(\forall_{i \in I, s_i \not\in S_i}) \sum_{s_{-i} \in S_{-i}} \sigma_{-i}(s_{-i}) u_i(s_i, s_{-i}) \leq v_i$$
$$(\forall_{i \in I} \sum_{s_i \in S_i}) \sigma_i(s_i) = 1$$
$$(\forall_{i \in I, s_i \in S_i}) \sigma_i(s_i) \geq 0$$
$$(\forall_{i \in I, s_i \not\in S_i}) \sigma_i(s_i) = 0$$
\end{algorithmic}
\end{algorithm}

Dysponując tym programem autorzy definiują pewien sposób wybierania profili, które mogą być testowane pod kątem bycia
równowagą Nasha. Ich algorytm rozpatruje z osobna przypadki dla wsparć o różnych rozmiarach, preferując mniejsze oraz
bardziej zbalansowane. Usuwane są też strategie warunkowo zdominowane. Pełna definicja programu jest przedstawiona jako
\textbf{Algorytm \ref{PNS2}}.

\begin{algorithm}
\caption{PNS dla 2 graczy}
\label{PNS2}
\begin{algorithmic}
\FORALL{możliwe rozmiary wsparcia profili $x = (x_1, x_2)$ posortowane rosnąco wg. najpierw $\ABS{x_1 - x_2}$, a
następnie $x_1 + x_2$}
 \FORALL{$S_1^{*} \subseteq S_1$ takich, że $\ABS{S_1^{*}} = x_1$ (zbiorów strategii niezdominowanych pierwszego gracza 
 o rozmiarze $x_1$)}
  \STATE $S_2' \ASSIGN \{ s_2 \in S_2: s_2 \textrm{ nie warunkowo zdominowane wzgl. } S_1 \}$
  \IF{$(\not\exists_{s_1 \in S_1}) \textrm{ nie warunkowo zdominowana wzg. } S_2'$}
   \FORALL{$S_2^{*} \subseteq S_2$ takich, że $\ABS{S_2^{*} = x_2}$ (zbiorów strategii niezdominowanych drugiego gracza
   o rozmiarze $x_2$)}
    \IF{$(\not\exists_{s_1 \in S_1}) \textrm{ nie warunkowo zdominowana wzg. } S_2^{*}$}
      \IF{zachodzi spełnialność równowagi Nasha dla profilu wspierającego}
       \RETURN{równowaga Nasha $s^{*}$}
      \ENDIF
    \ENDIF
   \ENDFOR
  \ENDIF
 \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

Wedle badań dokonanych przez autorów testy dokonane na pakiecie GAMUT algorytm ten zachowuje się dużo lepiej niż
najczęściej opisywany algorytm Lemkego-Howsona. Zestaw ten jest powszechnie używany do testowania poprawności
i wydajności różnych algorytmów z zakresu teorii gier, tak więc poprawa wyników w tych testach stanowi silny argument
przemawiający za wdrożeniem nowego rozwiązania.\cite{GAMUT}

Algorytm \textbf{Sandholma-Gilpina-Conitzera}\cite{SCG-NE} w podstawowej wersji definiuje kilka ograniczeń, dbających o
to, aby otrzymane wartości zawsze stanowiły poprawne rozwiązanie (równowagę Nasha). Są to ograniczenia \textit{problemu
całkowitoliczbowego}\INENG{integer programming}, rodzaju problemu LP, w którym wymagamy, aby przynajmniej jedna ze
zmiennych miała wartość całkowitą. Podstawowy wariant nie definiuje jednak funkcji celu, pozwalając jego użytkownikom
na samodzielne zdefiniowanie dowolnej liniowej (lub całkowitoliczbowej) funkcji celu.

Wykorzystane są: 
\begin{itemize}
\item zmienna $p_{s_i}$ - prawdopodobieństwo grania strategii $s_i$,
\item zmienna pomocnicza $U_i$. Dla gracza $i$ zmienna ta oznacza różnicę między maksymalnym (dla $s_i^h$) i minimalnym
(dla $s_i^l$) zyskiem jaki może on osiągnąć:
$$U_i = \max_{s_i^h, s_i^l \in S_i, s_{-i}^h, s_{-i}^l \in S_{-i}} u_i(s_i^h, s_{-i}^h) - u_i(s_i^l, s_{-i}^l)$$
\item zmienna $u_{s_i}$ - oznacza ono oczekiwaną wypłatę gracza grającego $s_i$ dla obecnej strategii mieszanej drugiego
gracza,
\item zmienną $r_{s_i}$ - ,,żal''\INENG{regret}. Wartość określającą różnicę między maksymalnym oczekiwanym zyskiem dla
pewnej strategii czystej, a wartością oczekiwaną dla $s_i$,
\item zmienna binarna $b_{s_i}$ - dla wartości równej $1$, prawdopodobieństwo użycia strategii $s_i$ jest zerowe,
dla $0$, może ona się pojawić o ile żal wyniesie $0$.
\end{itemize}

Wówczas ograniczenia możemy zdefiniować następująco $(\forall_{i \in I})$:
\begin{equation}
\sum_{{s_i} \in S_i} p_{s_i} = 1 \label{SGC2a}
\end{equation}
\begin{equation}
(\forall_{s_i \in S_i}) u_{s_i} = \sum_{s_{-i} \in S_{-i}} p_{s_{-i}} u_i(s_i, s_{-i}) \label{SGC2b}
\end{equation}
\begin{equation}
(\forall_{s_i \in S_i}) u_i \geq u_{s_i} \label{SGC2c}
\end{equation}
\begin{equation}
(\forall_{s_i \in S_i}) r_{s_i} = u_i - u_{s_i} \label{SGC2d}
\end{equation}
\begin{equation}
(\forall_{s_i \in S_i}) p_{s_i} \leq 1-b_{s_i} \label{SGC2e}
\end{equation}
\begin{equation}
(\forall_{s_i \in S_i}) r_{s_i} \leq U_i b_{s_i} \label{SGC2f}
\end{equation}

Ograniczenie \ref{SGC2a} gwarantuje nam, że $p_i$ będzie określać nam rozkład nad strategiami $s_i \in S_i$ gracza $i$.
\ref{SGC2b} oblicza wartość oczekiwaną wypłaty dla strategii czystej $s_i$ gracza $i$ przy obecnej strategii mieszanej
gracza $-i$. Warunek \ref{SGC2c} sprawia, że $u_i$ zawiera najmniejszą możliwą wartość oczekiwaną wypłaty dla strategii
czystych gracza $i$ (tym samym stanowi ograniczenie dolne wypłaty dla strategii mieszanej, jaką otrzyma przy obecnej
strategii mieszanej gracza $-i$). Ograniczenie \ref{SGC2d} oblicza żal dla każdej ze strategii. \ref{SGC2e} gwarantuje,
że $b_{s_i}$ będzie zmienną binarną określającą, czy strategia jest używana (jej prawdopodobieństwo jest niezerowe).
\ref{SGC2f}, upewnia nas, że żal nigdy nie przekroczy wartości maksymalnej dla strategii w użyciu oraz będzie równy $0$
dla strategii, dla których prawdopodobieństwo wynosi $0$.

Po dodaniu do tak zdefiniowanego problemu całokowitoliczbowego funkcji celu, każde osiągalne rozwiązanie będzie stanowić
poprawne rozwiązanie. \cite[str.~2]{SCG-NE}

Autorzy algorytmu w dalszej części swojej pracy omawiają 3 kolejne specjalizacje tego problemu:
\begin{enumerate}
\item wprowadzenie,,kary''\INENG{penalty} za żal, a następnie dążenie do jego minimalizacji - ograniczenia \ref{SGC2a},
\ref{SGC2b}, \ref{SGC2c}, \ref{SGC2d}, \ref{SGC2e} oraz:
$$\textbf{minimalizuj} \sum_{i \in \{0,1\}} \sum_{s_i \in S_i} f_{s_i} - U_i b_{s_i}$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) f_{s_i} \geq r_{s_i}$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) f_{s_i} \geq U_i b_{s_i}$$
\cite[str.~2]{SCG-NE}

Tutaj $f_{s_i}$ stanowi ,,karę'' za żal - dla danej strategii jest to $\max \{ r_{s_i}, U_i b_{s_i} \}$. Funkcja celu
sumuje żale wszystkich graczy i odejmuje od każdej z nich wartość $U_{s_i}$ - w efekcie strategie niewykorzystane są
usuwane z sumy, a prawdopodobne pozostają. Ostateczna wartość stanowi sumę wszystkich żali z prawdopodobnych strategii.

\item uzależnienie minimalizowanej ,,kary'' od prawdopodobieństwa wykorzystania strategii z niezerowym żalem
- ograniczenia \ref{SGC2a}, \ref{SGC2b}, \ref{SGC2c}, \ref{SGC2d}, \ref{SGC2f} oraz:
$$\textbf{minimalizuj} \sum_{i \in \{0,1\}} \sum_{s_i \in S_i} g_{s_i} - (1 - b_{s_i})$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) g_{s_i} \geq p_{s_i}$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) g_{s_i} \geq 1 - b_{s_i}$$
\cite[str.~2]{SCG-NE}

Tak sformułowany problem działa w podobny sposób do poprzedniego. Funkcja celu stanowi sumę wszystkich
prawdopodobieństw strategii z niezerowym żalem ($g_{s_i}$).

\item uzależnienie minimalizowanej ,,kary'' zarówno od wartości żalu danej strategii, jak i prawdopodobieństwa jej
wystąpienia - ograniczenia \ref{SGC2a}, \ref{SGC2b}, \ref{SGC2c}, \ref{SGC2d} oraz:
$$\textbf{minimalizuj} \sum_{i \in \{0,1\}} \sum_{s_i \in S_i} f_{s_i} + g_{s_i}$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) f_{s_i} \geq \frac{r_{s_i}}{U_i}$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) f_{s_i} \geq b_{s_i}$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) g_{s_i} \geq p_{s_i}$$
$$(\forall_{i \in I}) (\forall_{s_i \in S_i}) g_{s_i} \geq 1 - b_{s_i}$$
\cite[str.~2--3]{SCG-NE}

Jest to przekształcenie dwóch pierwszych problemów do postaci, w której możemy sumować zarówno wartości żalu
prawdopodobnych strategii jak i prawdopodobieństwa strategii o niezerowym żalu.
\end{enumerate}

Spośród wyżej wymienionych algorytmów zdecydowano się na przetestowanie działania ostatniego rozwiązania. Jest ono
relatywnie nowe, a więc nie posiada wielu praktycznych implementacji - stworzenie i udostępnienie takowej może być
istotniejszym wkładem badawczym niż tworzenie kolejnej wersji powszechnie stosowanego algorytmu.

\subsubsection{Gry o większej liczbie graczy}

Dla gier o większej liczbie graczy istnieją odpowiednie algorytmy do szukania równowagi Nasha. Jednymi z częściej
wymienianych są:
\begin{description}
\item[algorytm Scarfa] - najstarszy z wymienionych, powstał jako dowód konstrukcyjny istnienia równowag mieszanych
w grach $n$-osobowych \cite{SCARF-NR},
\item[algorytm Portera-Nudelmana-Shohama] dla $n > 2$ graczy. \cite{PNS-NE}.
\end{description}
Definicja algorytmu Scarfa jest zbyt obszerna, aby opisywać ją w niniejszej pracy z należytą starannością. Dokładniej
opiszemy więc wyłącznie drugi z algorytmów.

Algorytm \textbf{Portera-Nudelmana-Shohama}\cite{PNS-NE} dla $n > 2$ graczy jest bardziej złożony niż jego wersja
2-osobowa. Wykorzystuje on dwie kolejne procedury - rekurencyjne przeglądanie profili z nawrotami\INENG{Recursive
Backtracking} oraz iteracyjne usuwanie strategii zdominowanych\INENG{Iterated Removal of Strictly Dominated Strategies}
(IRSDS).

Procedura IRSDS przegląda przekazany jej profil dziedzin wszystkich graczy i dla każdego kolejnego gracza usuwa
wszystkie zdominowane strategie czyste, tak długo, jak po przejrzeniu wszystkich graczy w danej iteracji zmieniony 
został przynajmniej jeden z zbiorów strategii. (\textbf{Algorytm \ref{IRSDS}}.)

\begin{algorithm}
\caption{IRSDS}
\label{IRSDS}
\begin{algorithmic}
\REQUIRE{$D = (D_1, ..., D_n)$ - profil dziedzin}
\ENSURE{zaktualizowane zbiory lub \textit{failure}}
\REPEAT
 \STATE $\textrm{zmieniono} \ASSIGN \textrm{false}$
 \FORALL{$i \in I$}
  \FORALL{$s_i \in d_i \in D_i$}
   \FORALL{$s_i' \in S_i$}
    \IF{$(\forall_{s_{-i}) \in d_{-i} \in D_{-i}} u_i(s_i,s_{-i}) < u_i(s_i',s_{-i})$}
     \STATE $D_i \ASSIGN D_i - \{ d_i \in D_i: s_i \in d_i \}$
     \STATE $\textrm{zmieniono} \ASSIGN \textrm{true}$
     \IF{$D_i = \emptyset$}
      \RETURN{\textit{failure}}
     \ENDIF
    \ENDIF
   \ENDFOR 
  \ENDFOR
 \ENDFOR
\UNTIL{$\textrm{zmieniono} = \textrm{false}$}
\RETURN{$D$}
\end{algorithmic}
\end{algorithm}

Jest to wykorzystywane w rekurencyjnym przeszukiwaniu z nawrotami w następujący sposób: jeśli przekazane procedurze
wejście stanowi pełny profil dziedzin - uruchom program spełnialności \ref{FEASNE}. W przeciwnym wypadku dodaj kolejną
dziedzinę strategii do profilu (o wyborze gracza decyduje poziom zagłębienia wskazywany przez przekazywaną procedurze
zmienną), a następnie wywołaj rekurencyjnie procedurę i sprawdź czy odnaleziono równowagę Nasha. Jeśli tak - zwróć ją.
W przeciwnym wypadku iteruj dalej, aż do wyczerpania możliwości - jeśli równowaga nie zostanie odnaleziona zwróć
\textit{failure}. (\textbf{Algorytm \ref{RBT}}.)

\begin{algorithm}
\caption{Przeszukiwanie z nawrotami}
\label{RBT}
\begin{algorithmic}
\REQUIRE{$S = (S_1, ..., S_n)$ - profil wsparć, $D = {D_1, ..., D_n}$ - profil dziedzin, $i$ - indeks następnego
wsparcia do wybrania}
\ENSURE{Równowaga Nasha $p$ lub \textit{failure}}
\IF{$i = n+1$}
 \IF{Spełnialność zachodzi (\textbf{Algorytm \ref{FEASNE}}) dla $S$}
  \RETURN{Równowaga Nasha $p$}
 \ELSE
  \RETURN{\textit{failure}}
 \ENDIF
\ELSE
 \FORALL{$d_i \in D_i$}
  \STATE $S_i \ASSIGN d_i$
  \STATE $D_i \ASSIGN D_1 - \{ d_i \}$
  \IF{$IRSDS(S,D,i+1)$ (\textbf{Algorytm \ref{IRSDS}}) znajdzie równowagę Nasha $p$}
   \RETURN{$p$} 
  \ENDIF
 \ENDFOR 
 \RETURN{\textit{failure}}
\ENDIF
\end{algorithmic}
\end{algorithm}

Dysponując tymi procedurami wystarczy jedynie zainicjować wszystkie zmienne przy pierwszym wywołaniu procedury
(\textbf{Algorytm \ref{PNSN}}).

\begin{algorithm}
\caption{PNS dla $n > 2$ graczy}
\label{PNSN}
\begin{algorithmic}
\FORALL{$x = (x_1, ..., x_n)$ posortowane rosnąco wg. najpierw $\sum_{i \in I} x_i$, a następnie $\max_{i,j \in I}
(x_i - x_j$)}
 \STATE $(\forall_{i \in I}) S_i \ASSIGN NULL$
 \STATE $(\forall_{i \in I}) D_i \ASSIGN \{ S_i' \subseteq S_i : \ABS{S_i'} = x_i \}$
 \IF{przeglądanie z nawracaniem znajdzie równowagę $p$}
  \RETURN{$p$}
 \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

Tak zdefiniowany algorytm będzie się zachowywał jak uogólniona wersja algorytmu PNS dla 2 graczy. W istocie,
przyglądając się jego działaniu, możemy zauważyć, że ciało wersji 2-osobowej powstało przez zastąpienie wywołań
rozwinięciem funkcji, a usuwanie strategi zdominowanych realizowane jest na bieżąco, nie zaś przed rozpoczęciem
przeszukiwania ostatecznej przestrzeni rozwiązań.

Z braku czasu nie udało się jednak wdrożyć żadnego z tych algorytmów do ostatecznej wersji projektu. Implementacja
została więc tak zaplanowana, aby możliwe było wdrożenie wybranego z wyżej wymienionych algorytmów w przyszłości.

\section{Gra w postaci ekstensywnej}

\begin{definition}
\textbf{Grą w postaci ekstensywnej}\INENG{extensive-form game} nazywamy szóstkę, na którą składają się:
\begin{enumerate}
\item zbiór graczy,
\item porządek ruchów graczy,
\item funkcję wypłaty gracza od ciągu poczynionych ruchów,
\item wybory graczy dostępne w danym ruchu,
\item wiedza gracza w chwili podejmowania decyzji,
\item rozkład prawdopodobieństwa nad zdarzeniami zewnętrznymi (\textit{naturą}).
\end{enumerate}
\cite[str.~77--78]{FT-GT}
\end{definition}

Taką grę można przedstawić jako drzewo, którego liście zawierają wypłaty, węzły - momenty podejmowania decyzji przez
określonego gracza, a krawędzie odpowiadają konkretnym decyzjom (ruchom). Ścieżka od korzenia do liścia to ciąg decyzji
kolejnych graczy prowadzący do zakończenia gry i ustalenia wypłaty. Natura obrazuje zdarzenia losowe, bądź inne
czynniki, mające wpływ na losy gry, od których nie możemy jednak oczekiwać racjonalnego wybierania najkorzystniejszej
dla siebie strategii (nie przypisujemy im wypłaty). Z tego powodu wypłaty ścieżek przechodzących przez węzeł, w którym
decyduje natura, są wartościami oczekiwanymi po wypłatach w poszczególnych wychodzących z węzła poddrzewach (podgrach)
względem przypisanego danemu węzłowi natury rozkładowi prawdopodobieństwa. Zbiór informacyjny stanowi opis wiedzy
gracza o jego położeniu w chwili podejmowania decyzji. Jeśli kilka wierzchołków należy do tego samego zbioru
informacyjnego, gracz nie jest w stanie stwierdzić w którym z nich się znajduje. Pozwala to opisywać np. stan gracza po
zdarzeniu losowym lub brak informacji o ruchach przeciwników.

\subsection{Równowagi w strategiach czystych w grach z pełną informacją}

\begin{definition}
\textbf{Gra z pełną informacją}\INENG{complete information} to gra, w której każdy z graczy w dowolnym
momencie jest poinformowany o wszystkich wiodących do danej chwili ruchach - każdy wierzchołek należy do
jednoelementowego zbioru informacyjnego.
\cite[str.~81]{FT-GT}
\end{definition}

W przypadku gry w postaci ekstensywnej oznacza to, że możemy ją poprawnie sprowadzić do postaci, gdzie każdy węzeł
znajduje się w jednoelementowym zbiorze informacyjnym. Z kolei taka gra posiada interesującą właściwość: wiedząc gdzie
dokładnie znajdujemy się w drzewie gry, zawsze możemy wybrać optymalną strategię, jeśli tylko wiemy jakie wypłaty
ostatecznie otrzymalibyśmy dla każdej z możliwości. Ponieważ mamy do czynienia z graczami racjonalnymi możemy spodziewać
się, że również oni wybraliby optymalne dla siebie strategie.

\begin{theorem}
Każda gra w postaci ekstensywnej z pełną informacją posiada równowagę Nasha w strategiach czystych.
\cite[str.~91]{FT-GT}
\end{theorem}

Dysponując kompletną informacją możemy schodzić w głąb drzewa gry, aby ostatecznie dojść do liści zawierających wypłaty.
Na tym poziomie bieżący gracz posiada już wszystkie informacje potrzebne do podjęcia najkorzystniejszej dla siebie
decyzji. Gracz rozgrywający w poprzedzającym kroku jest z kolei w stanie ją przewidzieć. W ten sposób wychodząc od liści
i przesuwając się ,,w górę'' drzewa gry, dochodzimy w końcu do punktu wyjściowego - w tym momencie znamy już wszystkie
decyzje jakie podjęliby gracze, a tym samym ich wypłaty. Jest to optymalna wartość wypłaty dla każdego z nich i żaden
nie chciałby od niej odstąpić - tym samym odnaleźlibyśmy równowagę Nasha w tej grze.

\subsection{Inne gry w postaci ekstensywnej}

W grach bez pełnej informacji sytuacja komplikuje się. Z zbiorze informacyjnym może znajdować się kilka węzłów.
Wówczas nie wiemy dokładnie w którym z nich się znajdujemy, zaś dla każdego z nich inny wybór strategii może być tym
optymalnym. Proste przejrzenie drzewa od liści do korzenia nie pozwoli nam więc w oczywisty sposób wybrać najlepszych
strategii.

W takiej sytuacji można jednak znaleźć równowagę Nasha w \textbf{strategiach mieszanych} lub \textbf{postępowania}.

\begin{definition}
\textbf{Strategie mieszane} definiuje się analogicznie jak w grach w postaci strategicznej - istotny jest jednak fakt,
że strategią czystą jest jednoczesne podjęcie przez gracza decyzji dla każdego jego wierzchołka i to nad takimi
kompletnymi decyzjami jest ustanawiany rozkład.
\end{definition}

\begin{definition}
\textbf{Strategie postępowania}\INENG{behavior strategy} w przeciwieństwie do strategii mieszanych przypisują rozkłady
prawdopodobieństwa, nie całym strategiom czystym, ale ruchom możliwym do wykonania w poszczególnych wierzchołkach.
\cite[str.~83]{FT-GT}
\end{definition}

Ponownie ograniczenia czasowe spowodowały, że jedynie najprostszy do rozpatrzenia przypadek wszedł w skład implementacji
projektu, zaś poszukiwanie równowag w strategiach mieszanych i postępowania przeznaczono do zaimplementowania
w przyszłości.

\end{document}
